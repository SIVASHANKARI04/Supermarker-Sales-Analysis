import pandas as pd
import seabon as sns

df=pd.read_csv("E:\DSDemo\env\project\Demoprojects\supermarket_sales new.csv")
df

for i in df.columns:
    print(i,df[i].nunique())

df.isnull().sum()
df.duplicated().sum()
from sklearn.preprocessing import OrdinalEncoder
encode=OrdinalEncoder()
df
df.info()
df.describe()
df.shape

'Gender']=encode.fit_transform(df[["Gender"]])
df['Branch']=encode.fit_transform(df[["Branch"]])
df['City']=encode.fit_transform(df[["City"]])
df['Customer type']=encode.fit_transform(df[["Customer type"]])
df['Product line']=encode.fit_transform(df[["Product line"]])
df['Invoice ID']=encode.fit_transform(df[["Invoice ID"]])

df.info()
df.corr()

df.columns
for i in df.columns:
    print(i,df[i].nunique())

from scipy import stats

continues=["Unit price","Tax 5%","Invoice ID"]
categories=["Gender","Branch","City","Customer type","Product line","Quantity"]


from scipy import stats

def two_sample(d1,d2):
  t=0
  f=0
  for i in  range(31):
    sample1=d1.sample(frac=0.03)
    sample2=d2.sample(frac=0.03)
    t_test,p_value=stats.ttest_ind(sample1,sample2)
    if p_value < 0.055:
      f=f+1
    else:
      t=t+1
  if t>f:
    return True
  else:
    return False

#defining function for categories vs categories
def chisqare_cat_vs_cat(d1,d2):
  return True if stats.chi2_contingency(pd.crosstab(d1,d2))[1] < 0.055 else False

def annova_test(d1,d2):
  group=df[d2].unique()
  data={}
  for i in group:
    data[i]=df[d1][df[d2]==i]
  f_value,p_value=stats.f_oneway(*[i for i in data.values()])  #task for baby
  if p_value < 0.055:
    return False
  else:
    return True

final={}
for i in df.columns:
  final[i]={}
  for j in df.columns:
    if (i in continues) and (j in continues):
      result=two_sample(df[i],df[j])
    elif  (i in continues) and (j in categories):
      result=annova_test(i,j)
    elif (i in categories) and (j in continues):
      result=annova_test(j,i)
    elif (i in categories) and (j in categories):
      result=chisqare_cat_vs_cat(df[i],df[j])
    if result:
      final[i][j]=1
    else:
      final[i][j]=0

  import pprint
pprint.pprint(final)

final_df=pd.DataFrame(final)
final_df

sns.heatmap(final_df,cmap="coolwarm",annot=True)

for i in continues:
    print(i,df[i].skew(),df[i].kurtosis())

from scipy import stats
method=[0,0.5,-0.5,1,-1,2,-2]
for i in method:
    print(i)
    print("skewness",pd.DataFrame(stats.boxcox(df['Tax 5%'],lmbda=i)).skew().values,"kutosis",pd.DataFrame(stats.boxcox(df["Tax 5%"],lmbda=i)).kurtosis().values)
print("******************************************************")

df['Tax 5%']=stats.boxcox(df["Tax 5%"],lmbda=0)
df["Tax 5%"].skew()

x=df.drop("Unit price",axis=1)
y=df["Unit price"]

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)

from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error

from sklearn.linear_model import LinearRegression
model1=LinearRegression().fit(x_train,y_train)
y_pred=model1.predict(x_test)
print(mean_squared_error(y_test,y_pred))
print(mean_absolute_error(y_test,y_pred))
print(r2_score(y_test,y_pred))

from sklearn.ensemble import RandomForestRegressor
model2=RandomForestRegressor().fit(x_train,y_train)
y_pred=model2.predict(x_test)
print(mean_squared_error(y_test,y_pred))
print(mean_absolute_error(y_test,y_pred))
print(r2_score(y_test,y_pred))

from sklearn.svm import SVR
model3=SVR().fit(x_train,y_train)
y_pred=model3.predict(x_test)
print(mean_squared_error(y_test,y_pred))
print(mean_absolute_error(y_test,y_pred))
print(r2_score(y_test,y_pred))

from xgboost import XGBRegressor
model4=XGBRegressor().fit(x_train,y_train)
y_pred=model4.predict(x_test)
print(mean_squared_error(y_test,y_pred))
print(mean_absolute_error(y_test,y_pred))
print(r2_score(y_test,y_pred))

import pickle
with open("std.pkl","wb") as f1:
  pickle.dump(encode,f1)
